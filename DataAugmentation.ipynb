{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2694f4f",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-09-07T19:16:25.648962Z",
     "iopub.status.busy": "2024-09-07T19:16:25.648343Z",
     "iopub.status.idle": "2024-09-07T20:08:20.448897Z",
     "shell.execute_reply": "2024-09-07T20:08:20.445258Z"
    },
    "papermill": {
     "duration": 3114.813,
     "end_time": "2024-09-07T20:08:20.455328",
     "exception": false,
     "start_time": "2024-09-07T19:16:25.642328",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial class counts: {62: 3000, 40: 3000, 10: 1800, 34: 3068, 19: 3136, 47: 2999, 24: 2999, 6: 3751, 22: 2384, 78: 2202, 71: 2999, 67: 3000, 4: 3000, 13: 2156, 35: 3855, 7: 3409, 3: 2100, 65: 3872, 36: 2995, 70: 3474, 52: 1896, 41: 1772, 68: 10051, 37: 2457, 31: 2993, 50: 2378, 81: 2030, 25: 2996, 39: 2414, 64: 1892, 54: 2526, 43: 2014, 49: 4604, 61: 2381, 30: 3039, 18: 4235, 73: 3970, 27: 2637, 38: 2992, 72: 4582, 44: 3000, 74: 1438, 77: 3178, 33: 3575, 69: 2996, 1: 11494, 17: 2260, 48: 2993, 9: 3592, 29: 2999, 45: 5840, 26: 1758, 75: 4249, 23: 3000, 76: 2166, 66: 2496, 32: 2826, 20: 514, 55: 5778, 28: 3482, 14: 2199, 59: 5160, 58: 3000, 79: 1880, 57: 3245, 63: 3195, 15: 1224, 21: 10536, 80: 3645, 0: 4386, 16: 2447, 56: 3096, 53: 2770, 11: 2108, 5: 1026, 51: 2295, 60: 3275, 2: 602, 12: 3559, 8: 3629, 42: 3340, 46: 1848}\n",
      "Downsampling class 34 from 3068 to 3000\n",
      "Downsampling class 19 from 3136 to 3000\n",
      "Downsampling class 6 from 3751 to 3000\n",
      "Downsampling class 35 from 3855 to 3000\n",
      "Downsampling class 7 from 3409 to 3000\n",
      "Downsampling class 65 from 3872 to 3000\n",
      "Downsampling class 70 from 3474 to 3000\n",
      "Downsampling class 68 from 10051 to 3000\n",
      "Downsampling class 49 from 4604 to 3000\n",
      "Downsampling class 30 from 3039 to 3000\n",
      "Downsampling class 18 from 4235 to 3000\n",
      "Downsampling class 73 from 3970 to 3000\n",
      "Downsampling class 72 from 4582 to 3000\n",
      "Downsampling class 77 from 3178 to 3000\n",
      "Downsampling class 33 from 3575 to 3000\n",
      "Downsampling class 1 from 11494 to 3000\n",
      "Downsampling class 9 from 3592 to 3000\n",
      "Downsampling class 45 from 5840 to 3000\n",
      "Downsampling class 75 from 4249 to 3000\n",
      "Downsampling class 55 from 5778 to 3000\n",
      "Downsampling class 28 from 3482 to 3000\n",
      "Downsampling class 59 from 5160 to 3000\n",
      "Downsampling class 57 from 3245 to 3000\n",
      "Downsampling class 63 from 3195 to 3000\n",
      "Downsampling class 21 from 10536 to 3000\n",
      "Downsampling class 80 from 3645 to 3000\n",
      "Downsampling class 0 from 4386 to 3000\n",
      "Downsampling class 56 from 3096 to 3000\n",
      "Downsampling class 60 from 3275 to 3000\n",
      "Downsampling class 12 from 3559 to 3000\n",
      "Downsampling class 8 from 3629 to 3000\n",
      "Downsampling class 42 from 3340 to 3000\n",
      "Downsampling and augmentation complete. Final class counts:\n",
      "Class 62: 3000\n",
      "Class 40: 3000\n",
      "Class 10: 3000\n",
      "Class 34: 3068\n",
      "Class 19: 3136\n",
      "Class 47: 3004\n",
      "Class 24: 3004\n",
      "Class 6: 3751\n",
      "Class 22: 3004\n",
      "Class 78: 3002\n",
      "Class 71: 3004\n",
      "Class 67: 3000\n",
      "Class 4: 3000\n",
      "Class 13: 3001\n",
      "Class 35: 3855\n",
      "Class 7: 3409\n",
      "Class 3: 3000\n",
      "Class 65: 3872\n",
      "Class 36: 3000\n",
      "Class 70: 3474\n",
      "Class 52: 3001\n",
      "Class 41: 3002\n",
      "Class 68: 10051\n",
      "Class 37: 3002\n",
      "Class 31: 3003\n",
      "Class 50: 3003\n",
      "Class 81: 3000\n",
      "Class 25: 3001\n",
      "Class 39: 3004\n",
      "Class 64: 3002\n",
      "Class 54: 3001\n",
      "Class 43: 3004\n",
      "Class 49: 4604\n",
      "Class 61: 3001\n",
      "Class 30: 3039\n",
      "Class 18: 4235\n",
      "Class 73: 3970\n",
      "Class 27: 3002\n",
      "Class 38: 3002\n",
      "Class 72: 4582\n",
      "Class 44: 3000\n",
      "Class 74: 3003\n",
      "Class 77: 3178\n",
      "Class 33: 3575\n",
      "Class 69: 3001\n",
      "Class 1: 11494\n",
      "Class 17: 3000\n",
      "Class 48: 3003\n",
      "Class 9: 3592\n",
      "Class 29: 3004\n",
      "Class 45: 5840\n",
      "Class 26: 3003\n",
      "Class 75: 4249\n",
      "Class 23: 3000\n",
      "Class 76: 3001\n",
      "Class 66: 3001\n",
      "Class 32: 3001\n",
      "Class 20: 3004\n",
      "Class 55: 5778\n",
      "Class 28: 3482\n",
      "Class 14: 3004\n",
      "Class 59: 5160\n",
      "Class 58: 3000\n",
      "Class 79: 3000\n",
      "Class 57: 3245\n",
      "Class 63: 3195\n",
      "Class 15: 3004\n",
      "Class 21: 10536\n",
      "Class 80: 3645\n",
      "Class 0: 4386\n",
      "Class 16: 3002\n",
      "Class 56: 3096\n",
      "Class 53: 3000\n",
      "Class 11: 3003\n",
      "Class 5: 3001\n",
      "Class 51: 3000\n",
      "Class 60: 3275\n",
      "Class 2: 2877\n",
      "Class 12: 3559\n",
      "Class 8: 3629\n",
      "Class 42: 3340\n",
      "Class 46: 3003\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "\n",
    "# Define paths\n",
    "image_folder = '/kaggle/input/fvsaugmented/images'\n",
    "label_folder = '/kaggle/input/fvsaugmented/labels'\n",
    "output_image_folder = '/kaggle/working/images'\n",
    "output_label_folder = '/kaggle/working/labels'\n",
    "\n",
    "# Create output folders if they don't exist\n",
    "os.makedirs(output_image_folder, exist_ok=True)\n",
    "os.makedirs(output_label_folder, exist_ok=True)\n",
    "\n",
    "def read_label(label_path):\n",
    "    with open(label_path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    return [line.strip().split() for line in lines]  # Return list of labels\n",
    "\n",
    "def write_label(label_path, label_data):\n",
    "    with open(label_path, 'w') as f:\n",
    "        f.write('\\n'.join([' '.join(map(str, line)) for line in label_data]))\n",
    "\n",
    "# Count instances of each class and copy files to the working directory\n",
    "class_count = {}\n",
    "image_dict = {}  # Store images by class\n",
    "\n",
    "for label_file in os.listdir(label_folder):\n",
    "    label_path = os.path.join(label_folder, label_file)\n",
    "    label_data = read_label(label_path)\n",
    "    \n",
    "    for label in label_data:\n",
    "        try:\n",
    "            class_id = int(label[0])  # Get the class_id from the first element\n",
    "            class_count[class_id] = class_count.get(class_id, 0) + 1\n",
    "            \n",
    "            if class_id not in image_dict:\n",
    "                image_dict[class_id] = []\n",
    "            image_dict[class_id].append(label_file.replace('.txt', '.jpg'))  # Store image filename for downsampling\n",
    "        except (IndexError, ValueError) as e:\n",
    "            print(f\"Error processing label in file {label_file}: {e}\")\n",
    "        \n",
    "        # Copy files to the output (writable) directory\n",
    "        image_file = label_file.replace('.txt', '.jpg')\n",
    "        shutil.copy(os.path.join(image_folder, image_file), output_image_folder)\n",
    "        shutil.copy(os.path.join(label_folder, label_file), output_label_folder)\n",
    "\n",
    "# Print initial class count summary\n",
    "print(\"Initial class counts:\", class_count)\n",
    "# Function to perform image augmentations\n",
    "def random_shadow(image):\n",
    "    shadow = tf.random.uniform(tf.shape(image)[:2], 0.7, 1.0)\n",
    "    shadow = tf.image.resize(shadow[..., tf.newaxis], [tf.shape(image)[0], tf.shape(image)[1]])\n",
    "    return image * shadow\n",
    "\n",
    "def random_zoom(image):\n",
    "    zoom_factor = tf.random.uniform([], 0.8, 1.0)\n",
    "    h, w = tf.shape(image)[0], tf.shape(image)[1]\n",
    "    crop_size = tf.cast([h, w], tf.float32) * zoom_factor\n",
    "    crop_size = tf.cast(crop_size, tf.int32)  # Cast to int32 after multiplication\n",
    "    image = tf.image.random_crop(image, [crop_size[0], crop_size[1], 3])\n",
    "    return tf.image.resize(image, [h, w])\n",
    "\n",
    "def random_shift(image):\n",
    "    return tf.image.random_crop(tf.pad(image, [[25, 25], [25, 25], [0, 0]]), tf.shape(image))\n",
    "\n",
    "def random_shear(image):\n",
    "    shear_factor = tf.random.uniform([], -0.2, 0.2)\n",
    "    shear_matrix = [1, shear_factor, 0, 0, 1, 0, 0, 0]\n",
    "    shear_matrix = tf.reshape(shear_matrix, (8,))\n",
    "    \n",
    "    # Applying the shear transformation with a fill value of 0 (black)\n",
    "    return tf.raw_ops.ImageProjectiveTransformV3(\n",
    "        images=tf.expand_dims(image, 0),\n",
    "        transforms=[shear_matrix],\n",
    "        output_shape=tf.shape(image)[:2],\n",
    "        interpolation=\"BILINEAR\",\n",
    "        fill_mode=\"REFLECT\",\n",
    "        fill_value=0.0  # Fill value for out-of-bound pixels\n",
    "    )[0]\n",
    "\n",
    "def augment_image(image):\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "\n",
    "    # Ensure the image size is sufficient for cropping\n",
    "    height, width = tf.shape(image)[0], tf.shape(image)[1]\n",
    "    crop_height, crop_width = min(224, height), min(224, width)\n",
    "    \n",
    "    # Random crop and resize\n",
    "    image = tf.image.random_crop(image, [crop_height, crop_width, 3])\n",
    "    image = tf.image.resize(image, [224, 224])\n",
    "\n",
    "    # Random flip\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.image.random_flip_up_down(image)\n",
    "\n",
    "    # Random rotation\n",
    "    image = tf.image.rot90(image, k=tf.random.uniform(shape=[], minval=0, maxval=4, dtype=tf.int32))\n",
    "\n",
    "    # Random zoom (80% chance)\n",
    "    if tf.random.uniform([]) > 0.2:\n",
    "        image = random_zoom(image)\n",
    "\n",
    "    # Random shift (80% chance)\n",
    "    if tf.random.uniform([]) > 0.2:\n",
    "        image = random_shift(image)\n",
    "\n",
    "    # Random shear (50% chance)\n",
    "    if tf.random.uniform([]) > 0.5:\n",
    "        image = random_shear(image)\n",
    "\n",
    "    # Add random shadows (50% chance)\n",
    "    if tf.random.uniform([]) > 0.5:\n",
    "        image = random_shadow(image)\n",
    "\n",
    "    # Gaussian noise (very subtle, to simulate different camera sensors)\n",
    "    noise = tf.random.normal(shape=tf.shape(image), mean=0.0, stddev=0.01, dtype=tf.float32)\n",
    "    image = tf.clip_by_value(image + noise, 0.0, 1.0)\n",
    "\n",
    "    return image\n",
    "# Downsample classes with more than 3000 instances\n",
    "for class_id, count in class_count.items():\n",
    "    if count > 3000:\n",
    "        print(f\"Downsampling class {class_id} from {count} to 3000\")\n",
    "        images_to_remove = random.sample(image_dict[class_id], count - 3000)\n",
    "        for img_file in images_to_remove:\n",
    "            image_path = os.path.join(output_image_folder, img_file)\n",
    "            label_path = os.path.join(output_label_folder, img_file.replace('.jpg', '.txt'))\n",
    "            \n",
    "            if os.path.exists(image_path):\n",
    "                os.remove(image_path)  # Remove the image\n",
    "            if os.path.exists(label_path):\n",
    "                os.remove(label_path)  # Remove the corresponding label\n",
    "\n",
    "# Perform augmentation for classes with fewer than 3000 images\n",
    "all_classes_reached_limit = False\n",
    "\n",
    "for image_file in os.listdir(output_image_folder):\n",
    "    if all_classes_reached_limit:\n",
    "        break\n",
    "    \n",
    "    image_path = os.path.join(output_image_folder, image_file)\n",
    "    label_path = os.path.join(output_label_folder, image_file.replace('.jpg', '.txt'))\n",
    "    \n",
    "    image = Image.open(image_path)\n",
    "    label_data = read_label(label_path)\n",
    "    \n",
    "    # Check if label_data is empty or improperly formatted\n",
    "    if not label_data or not label_data[0]:\n",
    "        print(f\"Skipping {image_file} due to empty or invalid label.\")\n",
    "        continue  # Skip this file if label data is empty or invalid\n",
    "    \n",
    "    class_id = int(label_data[0][0])\n",
    "    \n",
    "    # Augment if needed\n",
    "    if class_count[class_id] < 3000:\n",
    "        for i in range(5):\n",
    "            aug_image = augment_image(tf.convert_to_tensor(np.array(image)))\n",
    "            aug_image = Image.fromarray((aug_image.numpy() * 255).astype(np.uint8))\n",
    "\n",
    "            aug_image_file = f\"{image_file.split('.')[0]}_{class_count[class_id]}.jpg\"\n",
    "            aug_label_file = f\"{image_file.split('.')[0]}_{class_count[class_id]}.txt\"\n",
    "\n",
    "            aug_image.save(os.path.join(output_image_folder, aug_image_file))\n",
    "            write_label(os.path.join(output_label_folder, aug_label_file), label_data)\n",
    "\n",
    "            class_count[class_id] += 1\n",
    "    \n",
    "    # Check if all classes have reached the limit\n",
    "    if all(count >= 3000 for count in class_count.values()):\n",
    "        all_classes_reached_limit = True\n",
    "\n",
    "# Print final class counts\n",
    "print(\"Downsampling and augmentation complete. Final class counts:\")\n",
    "for class_id, count in class_count.items():\n",
    "    print(f\"Class {class_id}: {count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b63e646",
   "metadata": {
    "papermill": {
     "duration": 0.003973,
     "end_time": "2024-09-07T20:08:20.465658",
     "exception": false,
     "start_time": "2024-09-07T20:08:20.461685",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 5638755,
     "sourceId": 9310721,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5645680,
     "sourceId": 9335806,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30761,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 3120.918336,
   "end_time": "2024-09-07T20:08:23.555209",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-09-07T19:16:22.636873",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
